---
title: "Regresion de Series de Tiempo"
output: github_document
#output: html_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Regresión Lineal Saimple Con errores no-autocorrelacionados.

Vamos a tratar de relacionar los cambios porcentuales trimestrales del gasto real del consumo personal$(y)$ y el ingreso disponible real persona. Primero visualizamos las series, las cuales son al menos estables en media.

```{r datos reg1}
library(feasts)
library(fpp3)
data(us_change) ##Del paquete fpp3
str(us_change)
us_change %>%
  pivot_longer(c(Consumption, Income), names_to="Series") %>%
  autoplot(value) +
  labs(y = "% change")
```
También se puede usar el paquete timetk
```{r timetk}
library(timetk)
library(tidyquant)
library(stringr)
?timetk::plot_time_series()
Ts_multiple=us_change%>%pivot_longer(c(Consumption,Income,Production,Savings,Unemployment))
Ts_multiple$Quarter=as.Date(Ts_multiple$Quarter)
Ts_multiple%>%group_by(name)%>%timetk::plot_time_series(Quarter ,value,.facet_ncol  = 2,.interactive  = FALSE)

```


Llevemos a cabo ahora unas gráficas exploratorias.

```{r exploratoria reg1}
us_change %>%
  ggplot(aes(x = Income, y = Consumption)) +
  labs(y = "Consumption (quarterly % change)",
       x = "Income (quarterly % change)") +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

```

El anterior diagrama de dispersión no permite ver una relación lineal muy clara de forma instantánea.
Exploremos las autocorrelaciones.

```{r reg 1 autocorrelaciones}
us_change %>% ACF(Income,lag_max = 20) %>% 
  autoplot()

us_change %>% ACF(Consumption,lag_max = 20) %>% 
  autoplot()

us_change %>% CCF(Consumption,Income,lag_max = 20) %>% 
  autoplot()
```

Serán independientes las series??Usar el pre-blanqueamineto de las series(Tarea)

También usemos timetk para explorar las autocorrelaciones simples y parciales

```{r timetk correlaciones}
Ts_multiple%>%group_by(name)%>%plot_acf_diagnostics(Quarter ,value,.lags=30,.interactive=FALSE)
us_change%>%plot_acf_diagnostics(.date_var=Quater,.value=Consumption,.ccf_vars = c(Income,Production,Savings,Unemployment),.lags=15,.interactive=FALSE,.facet_ncol  = 2,.show_ccf_vars_only=TRUE)
```

Parece tener sentido que hagamos una regresión lineal simple para mirar la existencia de una relación contemporánea(es decir instantánea).

Ahora veamos el ajuste del modelo.

```{r ajuste reg1}
Ajustesreg1=us_change %>%
  model(TSLM(Consumption ~ Income)) %>%
  report()
```

Note que el poder explicativo del ingreso no es muy alto.

```{r gls}
salida_sincorrelacion=nlme::gls(Consumption ~ Income,us_change)
corr = nlme::corARMA(value=c(0.2,0.4),p = 1, q = 1)
corr=nlme::Initialize(corr,us_change)
nlme::corMatrix(corr)
dim(nlme::corMatrix(corr))
salida_concorrelacion=nlme::gls(Consumption ~ Income,us_change,correlation = corr)
summary(salida_concorrelacion)
library(lmtest)
coeftest(salida_concorrelacion)
```


## Verficación de los supuestos

```{r supuestos reg1}
Ajustesreg1%>% gg_tsresiduals()

```

La gráfica de los residuales no parece mostrar patrones sitemáticos(tendencia o ciclos), sin embargo si parecen estar autocorrelacionados. También parecen tener unos valores atípicos. Con esto, nos podemos dar cuenta que el ajuste del modelo no es bueno, lo cual implica que es necesario cambiar el modelo. Vamos ahora a considerar ahora un modelo donde se incluyan mas variables, también se puede considerar que tenga en cuenta la estructura de autocorrelación presente en los residuales.

## Regresión múltiple
Vamos ahora a considerar que los cambios porcentuales del consumo no solo es función de los cambios porcentuales ingreso sino también de otras variable como producción, desempleo y ahorros. Vamos primero a graficar las series de tiempode  las otras tres variables.

```{r timeplots Reg mult}
us_change %>%
  select(-Consumption, -Income) %>%
  pivot_longer(-Quarter) %>%
  ggplot(aes(Quarter, value, color = name)) +
  geom_line() +
  facet_grid(name ~ ., scales = "free_y") +
  guides(colour = "none") +
  labs(y="% change")
```
```{r timeplots Reg mult todas}
us_change %>%
 pivot_longer(c(Consumption,Income,Production,Savings,Unemployment)) %>%
  ggplot(aes(Quarter, value, color = name)) +
  geom_line() +
  facet_grid(name ~ ., scales = "free_y") +
  guides(colour = "none") +
  labs(y="% change")
```

Veamos ahora las descriptivas.

```{r descriptiva reg mul}
ts_todas=as.data.frame(us_change)
ts_todas_final=ts_todas[2:6]
acf(ts_todas_final,lag.max = 20)
```
Al chequear las correlaciones cruzadas del consumo con las otras variables vemos que parecer haber una relación temporal contemporánea.Recuerden que para que en efecto podamos estudiar bien las dependecias, hay que hacer un pre-blanqueo de almenos uno de las series, la cual en este caso la que parecer ser mas óptima es la serie de consumo que es la dependiente. Tarea(Hacer el pre-blanqueamiento de la serie consumo y chequear las autocorrelaciones cruzadas.)

```{r ccm reg mul}
x11()
MTS::ccm(ts_todas_final,lags=20)

```

```{r Diagrama de dispersión}
us_change %>%
  pivot_longer(Income:Unemployment,
               names_to = "regressor", values_to = "x") %>%
  ggplot(aes(x = x, y = Consumption)) +
  geom_point() +
  facet_wrap(. ~ regressor, scales = "free_x") +
  labs(y = "Consumption", x = "")
```


Con lo anteriormente mencionado podemos ver que hay una relación instantánea entre las variables explicativas y el consumo. Ahora corramos la regresión

```{r regresion mult Consumption}
fit_consMR <- us_change %>%
  model(tslm = TSLM(Consumption ~ Income + Production +
                                    Unemployment + Savings))
report(fit_consMR)
```

## Comparación de valores reales con los valores predichos

```{r comparacion predicho vs reales}
augment(fit_consMR) %>%
  ggplot(aes(x = Quarter)) +
  geom_line(aes(y = Consumption, colour = "Datos")) +
  geom_line(aes(y = .fitted, colour = "Ajustados")) +
  labs(y = NULL,
    title = "Porcentaje de Cambio en el consumo de US "
  ) +
  scale_colour_manual(values=c(Datos="black",Ajustados="#D55E00")) +
  guides(colour = guide_legend(title = NULL))

augment(fit_consMR) %>%
  ggplot(aes(x = Consumption, y = .fitted)) +
  geom_point() +
  labs(
    y = "Ajustados (Valores Predichos)",
    x = "Datos (Valores Reales)",
    title = "Porcentaje de Cambio en el consumo de US"
  ) +
  geom_abline(intercept = 0, slope = 1)

```



Para la evaluación del modelo, hay que chequear los supuestos básico de la regresión múltiple. 

```{r análisis de residuales}
library(tseries)
fit_consMR %>% gg_tsresiduals()

augment(fit_consMR) %>%
  features(.innov, ljung_box, lag = 10, dof = 5)

tseries::jarque.bera.test(augment(fit_consMR)$.innov)


```

## Relaciones Espurias

Cuando las series no son estacionarias(presentan tendencias), como sucede en muchas series de tiempo, el impacto pueden ser muy grande cuando se desea llevar a cabo la regresión. Puede suceder que aunque dos series de tiempo sean independientes pero no estacionarias, al llevar a cabo una regresión entre ellas, la regresión(lineal) nos muestre que si hay dependencia entre ellas. Eso lo conocemos como relaciones espurias. En el script de R vemos un ejemplo de simulación y un conjunto de datos reales. Mas adelante vemos como trabajar en este tipo de escenarios.

```{r simul espurias}
set.seed(123)
Xtind=arima.sim(n=500,list(order = c(0,1,0)))
set.seed(456)
Ytind=arima.sim(n=500,list(order = c(0,1,0)))
daily_index_simul <- as.Date(seq.Date(from = as.Date("2008-01-01"), # Starting date
                           length.out=500,
                           by = "day") )# Defining the time intervals to =       as.Date("2012-12-16"), # Ending date
df_simul=data.frame(Xtind=Xtind[2:501],Ytind=Ytind[2:501],daily_index_simul)
tibble_df_simul=tibble(df_simul)
ts_tibble_simul=as_tsibble(df_simul,index=daily_index_simul)
ts_tibble_simul_mult=ts_tibble_simul%>%pivot_longer(c(Xtind,Ytind),names_to = "serie",values_to = "valores")
ts_tibble_simul_mult%>%group_by(serie)%>%timetk::plot_time_series(daily_index_simul ,valores,.interactive  = FALSE)
```
Se lleva acabo las gráficas ACF, PACF, CCF y la regresión:

```{r regresion espurias no-estacionarias e independientes}
ts_tibble_simul %>% ACF(Ytind,lag_max = 20) %>% 
  autoplot()

ts_tibble_simul %>% ACF(Xtind,lag_max = 20) %>% 
  autoplot()

ts_tibble_simul %>% CCF(Ytind,Xtind,lag_max = 20) %>% 
  autoplot()

Ajustesreg1_espurias=ts_tibble_simul %>%
  model(TSLM(Ytind ~ Xtind)) %>%
  report()
```
Primero vale la pena señalar la fuerte autocorrelación cruzada entre las dos serie.Note ahora que los parámetros son altamente significativos, a pesar de que las series son independientes. Note que se propone la regresión:
$$y_t=\beta_0+\beta_1 x_t+\epsilon_t$$
donde $\{\epsilon_t\}$ es un proceso no autocorrelacionado en principio. Lo cual es equivalente a decir que
$$y_t-\beta_0-\beta_1 x_t=\epsilon_t,$$
es decir que existe una combinación lineal(\textit{de procesos no estacionarios que en este caso están integrados}) de $y_t$ y $x_t$ tal que es estacionaria, que es la definición de que los procesos están cointegrados o que hay una relación de cointegración entre esos procesos. Es decir, tiene sentido proponer una regresión lineal entre dos procesos no estacionarios, siempre que haya una relación de cointegración.

## Ejemplo Real Relaciones Espurias
Vamos a observar las series número de pasajeros anual en Australia y la producción anual de arroz en Guinea. En principio estas dos series no debería tener ninguna relación desde el punto de vista teórico y práctico. Ambas Series como veremos son no estacionarias y presentan tendencias.

```{r Espurias datos reales}
data("aus_airpassengers")
data("guinea_rice")
aus_airpassengers%>%timetk::plot_time_series(.value=Passengers,.date_var=Year,.smooth = FALSE)
guinea_rice%>%timetk::plot_time_series(.value=Production,.date_var=Year,.smooth = F)

```

```{r Espurias dispersión}
aus_airpassengers%>%left_join(guinea_rice,by="Year")%>%filter(Year<=2011) %>%ggplot(aes(x = Passengers, y = Production)) +
  geom_point() +
  labs(
    y = "Número de Pasajeros Aus(Millones)",
    x = "Producción de Arroz Guinea (Millones de Tons)",
    title = "Diagrama de Dispersión"
  ) 


ajuste_espurias=aus_airpassengers%>%left_join(guinea_rice,by="Year")%>%filter(Year<=2011) %>%model(fable::TSLM(Passengers~Production))
report(ajuste_espurias)

ajuste_espurias%>%feasts::gg_tsresiduals(type="innovation")
```
Note que el $R^2$ del ajuste es muy alto, pero también muestra una alta autocorrelación los residuales, lo cual un síntoma de relaciones espurias.

## Predictores útiles

```{r Intervencion}
library(readxl)
Desempleo<- read_excel("/Users/sergiocalderon/Documents/GitHub/TimeSeries/Series Univariadas/Bases de Datos/Desempleo.xlsx", col_types = c("text", "numeric"), col_names=c('Fecha','TasaDesempleo'),skip=1)
str(Desempleo)
Desempleo$Fecha= yearmonth(as.yearmon(Desempleo$Fecha))
ts_Desempleo=as_tsibble(Desempleo)
ts_Desempleo%>%timetk::plot_time_series(.value=TasaDesempleo,.date_var=Fecha,.smooth = F)

```

Note que debido al Covid, la tasa de desempleo creció durante el mes de Abril 2020, y se mantuvo por varios meses mas, sin embargo podemos notar que después de cierto periodo de tiempo, estamos regresando a los niveles que tenía la serie ante la pandemia. Esta intervención puede modelarse a través de variables dummy.Por ejemplo, si ajustamos un ARIMA automático a la serie y luego vemos si hay outliers, lo cuales se pueden modelar a través de intervenciones.

```{r Intervencion1}
library(tsoutliers)
ajuste_desempleo=ts_Desempleo%>%model(ARIMA(TasaDesempleo))
report(ajuste_desempleo)
ajuste_desempleo%>%coef()
autoarima_desempleo=forecast::auto.arima(ts_Desempleo)
resi= residuals(autoarima_desempleo)
coef= coefs2poly(autoarima_desempleo)
coef
outliers= tsoutliers::locate.outliers(resi,coef)
outliers
xreg = outliers.effects(outliers, length(resi))
xreg
```

##Dummy Estacionales

Vamos a crear Dummy Estacionales para modelar la Estacionalidad con base en la serie de producción de cerveza trimestral en Australia. Note que claramente hay un ciclo anual en esta serie trimestral.

```{r Dummy Estacionales}
recent_production <- aus_production %>%
  filter(year(Quarter) >= 1992)
recent_production %>%
  autoplot(Beer) +
  labs(y = "Megalitros",
       title = "producción de cerveza trimestral en Australia")

```

Vamos a ajustarle a esta serie un modelo con tendencia lineal y con dummy estacionales.La función season() reconoce inmediatamente que para una serie trimestral, el ciclo tiene un periodo de 4, mientras que trend() reconoce que un una tendencia lineal. El modelo a ajustarse es el siguiente:

$$y_t=\beta_0+\beta_1 t+\beta_2 d_{2,t}+\beta_3 d_{3,t}+\beta_4 d_{4,t}+\epsilon_t$$
La variable del primer trimestre fue omitida, tal que los coeficientes asociados con los otros trimestres son medidos de la diferencia  entre esos trimestres y el primer trimestre.
```{r Dummy estacionales 1}
fit_beer <- recent_production %>%
  model(TSLM(Beer ~ trend() + season()))
report(fit_beer)

```
 Los resultados se interpretan de la siguiente manera:
 Hay una tendencia media a la baja de -0,34 megalitros por trimestre. En promedio, el segundo trimestre tiene una producción de 34,7 megalitros menos que el primer trimestre, el tercer trimestre tiene una producción de 17,8 megalitros menos que el primer trimestre y el cuarto trimestre tiene una producción de 72,8 megalitros más que el primer trimestre.
 
 Vamos ahora a ver el ajuste del modelo intramuestra:
 
```{r dummy estacionales 2}
augment(fit_beer) %>%
  ggplot(aes(x = Quarter)) +
  geom_line(aes(y = Beer, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  scale_colour_manual(
    values = c(Data = "black", Fitted = "#D55E00")
  ) +
  labs(y = "Megalitros",
       title = "producción de cerveza trimestral en Australia") +
  guides(colour = guide_legend(title = "Series"))
```
 
## Componentes de Fourier
Vamos a hacer un ajuste haciendo una regresión con componentes de Fourier donde solo tomamos dos componentes en la suma. En este caso solo hay tres componentes de Fourier ya que el segundo componente del seno siempre va a dar cero.
```{r Fourier}
fourier_beer <- recent_production %>%
  model(TSLM(Beer ~ trend() + fourier(K = 2)))
report(fourier_beer)
```

## Pronóstico con Regresión

Vamos a ver como producir los pronósticos basados en el modelo de regresión lineal, y así mismo como producir los intervalos de pronóstico.

Vamos a utilizar las variables determinísticas para producir los pronósticos, en especial las variables dummy.El ejemplo que vamos a considerar que se desea predecir la producción trimestral de cerveza, la cual presenta una leve tendencia y una componente estacional, las cuales son modeladas por componentes determinísticas como se vió anteriormente. Para este caso los pronósticos ex-ante y ex-post resultan ser iguales.

```{r pronostico dummy}
 recent_production <- aus_production %>%
  filter(year(Quarter) >= 1992)
recent_production %>%
  autoplot(Beer) +
  labs(y = "Megalitros",
       title = "producción de cerveza trimestral en Australia")
tail(recent_production)

fit_beer <- recent_production %>%
model(TSLM(Beer ~ trend() + season()))
fc_beer<-fabletools::forecast(fit_beer,h=8)

fc_beer%>%
  autoplot(recent_production)+
  labs(title="Pronóstico de la producción de cerveza usando Regresión para 2 años",
y="Megalitros")
```

Note que no hay que crear los valores futuros de las variables determinísticas, la función misma lo crea.

Tarea: Hacer los mismo usando las variables de Fourier.

# Pronóstico basado en una variable predictora 

Supongamos que se desea predecir el consumo con base en en el ingreso. Adicionalmente vamos a hacer escenarios de
predicción cuando suponemos que hay un incremento en el ingreso por encima del promedio histórico de $\bar{x}=0.73\%$ apróximadamente, y cuando tenemos un valor de incremento extremo del $12\%$.
```{r pronostico una variable predictora y escenarios}
fit_cons <- us_change %>%
  model(TSLM(Consumption ~ Income))
new_cons <- scenarios(
  "Incremento Promedio" = new_data(us_change, 4) %>%
    mutate(Income = mean(us_change$Income)),
  "Incremento Extremo" = new_data(us_change, 4) %>%
    mutate(Income = 12),
  names_to = "Escenario"
)
new_cons

fcast <- forecast(fit_cons, new_cons)

us_change %>%
  autoplot(Consumption) +
  autolayer(fcast) +
  labs(title = "Consumo Us", y = "% cambio")
fcast
```


## Pronóstico basados en multiples variables predictoras  y escenarios

Por ejemplo, se está interesado en comparar el cambio predicho en el consumo cuando hay un crecimiento constante de $1\%$ y $0.5\%$ respectivamente para el ingreso y los ahorros, sin cambios en la tasa de desempleo, versus una caída respectiva de $1\%$ y $0.5\%$, para cada uno de los trimestres luego del final del periodo de la muestra.  Note que los intervalos de predicción calculados no tienen en cuenta la incertidumbre  asociada a los valores futuros de las variables predictoras.

```{r Pronostico basados en escenarios}
fit_consBest <- us_change %>%
  model(
    lm = TSLM(Consumption ~ Income + Savings + Unemployment)
  )

future_scenarios <- scenarios(
  Increase = new_data(us_change, 4) %>%
    mutate(Income=1, Savings=0.5, Unemployment=0),
  Decrease = new_data(us_change, 4) %>%
    mutate(Income=-1, Savings=-0.5, Unemployment=0),
  names_to = "Scenario")

future_scenarios

fc <- forecast(fit_consBest, new_data = future_scenarios)
us_change %>%
  autoplot(Consumption) +
  autolayer(fc) +
  labs(title = "Consumo US", y = "% change")

fc
```

Tarea:Hacer los mismo pero incluir incrementos de 0.25 en cada periodo, y además el desempleo del escenario de incremento empieza en 0.25. Realizar lo mismo pero para el escenario de decrecimiento pero valores negativos y el decrecimiento es de -0.25.

Leer sección 7.8 libro fpp3.

### Modelos de Regresión Dinámica

Vamos a considerar que los errores del modelo de regresión son $\{\eta_t\}$ tal que
  

 $$y_{t}=\beta_0+\beta_1 x_{1,t}+\cdots,+\beta_k x_{k,t}+\eta_t$$
 y que asumimos que el modelo de los errores es un $arima(p,d,q)$
 $$\phi(B)(1-B)^d\eta_t=\theta(B)\epsilon_t$$

donde $\{\epsilon_t\}\sim RB(0,\sigma^2)$, es decir, el modelo tiene dos errores, los errores de la regresión $\eta_t$, y el error del modelo $arima$ que es $\epsilon_t$ que es un ruido blanco.

Vamos a usar la función ARIMA de el paquete \textit{fable}.Supongamos que la función es usada de la siguiente manera:

$ARIMA(y~ x +pdq(1,1,1))$, lo cual ajustará un modelo
$$y_t'=\beta_1x_t'+\eta_t'$$
donde $y_t'=y_t-y_{t-1}$, $x_t'=x_t-x_{t-1}$ y $\eta_t'=\eta_t-\eta_{t-1}$ con $\eta_t'=\phi_1+\eta_{t-1}'+\epsilon_t$, el cual es equivalente al modelo
$$y_t=\beta_0+\beta_1x_t+\eta_t$$
donde $\{\eta_t\}\sim ARIMA(1,1,0)$. Es decir, si $d=1$ en el argumento, todos las series son diferenciadas.

## Ejemplo Consumo depende del ingreso

Vamos a suponer que los cambios consumo dependen de los cambios en el ingreso y que vamos a tener en cuenta la estructura de autocorrelación en los residuales, a diferencia del primer ejemplo de este script.

Vamos a considerar primero el modelo automático sugerido por la función $ARIMA$ para los errores. Veamos primero las dos serie a relacionar.

```{r regresión dinámica 1}
us_change %>%
  pivot_longer(c(Consumption, Income),
               names_to = "var", values_to = "value") %>%
  ggplot(aes(x = Quarter, y = value)) +
  geom_line() +
  facet_grid(vars(var), scales = "free_y") +
  labs(title = "US consumption and personal income",
       y = "Quarterly % change")

```

Ahora veamos el ajuste con una propuesta automática para el modelo de los errores.
```{r Regresión dinámica 2}

fit <- us_change %>%
  fabletools::model(fable::ARIMA(Consumption ~ Income))
report(fit)
coef(fit)
```

Note que las series están en diferencias y no en niveles, por lo cual el procedimiento no sugiere una diferencia.Además todos los parámetros resultan significativos.

Nota: Recuerde construir el modelo para los errores usando las herramientas del análisis univariado de series de tiempo.

Así el modelo queda expresando de la siguiente manera:
$$y_t=0.5949310+0.1976247x_t+\eta_t$$ 
donde
$$\eta_t-0.7070037\eta_{t-1}=\epsilon_t-0.6172115\epsilon_{t-1}+0.2066358\epsilon_{t-2}$$

tal que

$$\{\epsilon_t\}\sim NID(0,0.3113)$$


Ahora obtengamos los dos conjuntos de residuales del modelo propuesto y chequeemos como se comportan:

```{r regresion dinámica 3}
bind_rows(
    `Residuales de la Regresion` =
        as_tibble(residuals(fit, type = "regression")),
    `Residuals ARIMA` =
        as_tibble(residuals(fit, type = "innovation")),
    .id = "type"
  ) %>%
  mutate(
    type = factor(type, levels=c(
      "Residuales de la Regresion", "Residuals ARIMA"))
  ) %>%
  ggplot(aes(x = Quarter, y = .resid)) +
  geom_line() +
  facet_grid(vars(type))
```

Por supuesto los residuales del modelo ARIMA $\{\hat{\epsilon}_t\}$ deberían parecerse a un ruido blanco.

## Cheqeo de los Residuales del modelo

Veamos los residuales del modelo, es decir los residuales del modelo ARIMA.

```{r Regresión dinámica 4}
fit%>% feasts::gg_tsresiduals()

```

Qué podemos decir estos residuales comparados con el primer modelo que se ajustó?

Puede que queden outliers!!!

## Pronóstico   
Vamos a obtener el pronóstico del cambio porcentual del consumo para los siguientes 8 periodos o trimestres. Para esto, se asumirá que el cambio porcentual del ingreso será igual al porcentaje promedio de los últimos 40 años. Primero se crean los valores futuros, y luego se hace el pronóstico basados en el modelo ajustado.

```{r regresion dinámica pronostico}
us_change_future <- tsibble::new_data(us_change, 8) %>%
  dplyr::mutate(Income = mean(us_change$Income))
forecast(fit, new_data = us_change_future) %>%
  autoplot(us_change) +
  labs(y = "Cambio Porcentual")
```

